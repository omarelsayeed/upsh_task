{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6230373,"sourceType":"datasetVersion","datasetId":3578855},{"sourceId":6231223,"sourceType":"datasetVersion","datasetId":3579393},{"sourceId":6233171,"sourceType":"datasetVersion","datasetId":3580689},{"sourceId":6236662,"sourceType":"datasetVersion","datasetId":3582913},{"sourceId":6237831,"sourceType":"datasetVersion","datasetId":3583700},{"sourceId":6238436,"sourceType":"datasetVersion","datasetId":3584098},{"sourceId":6249488,"sourceType":"datasetVersion","datasetId":3591380},{"sourceId":6250126,"sourceType":"datasetVersion","datasetId":3591779},{"sourceId":6729525,"sourceType":"datasetVersion","datasetId":3876186},{"sourceId":6757056,"sourceType":"datasetVersion","datasetId":3889597},{"sourceId":6956563,"sourceType":"datasetVersion","datasetId":3995731},{"sourceId":7564418,"sourceType":"datasetVersion","datasetId":4404590},{"sourceId":7945635,"sourceType":"datasetVersion","datasetId":3734669},{"sourceId":8024368,"sourceType":"datasetVersion","datasetId":4728828},{"sourceId":8533833,"sourceType":"datasetVersion","datasetId":4968045},{"sourceId":8928253,"sourceType":"datasetVersion","datasetId":5370643}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install accelerate -U\n!pip install sentence-transformers\n\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer, LoggingHandler , models, util, datasets, evaluation, losses\nfrom torch.utils.data import DataLoader\nimport logging\nfrom huggingface_hub import login , HfApi\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sentiment/sentiment task - Sheet1.csv\")\ndf.columns = ['text' , \"label\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create pairs dataset","metadata":{}},{"cell_type":"code","source":"from itertools import combinations\npair_data = {'text1': [], 'text2': [], 'label': []}\nunique_labels = df['label'].unique()\n\nfor label in unique_labels:\n    samples_with_label = df[df['label'] == label]\n    pairs_same_class = list(combinations(samples_with_label['text'], 2))\n    pair_data['text1'].extend([pair[0] for pair in pairs_same_class])\n    pair_data['text2'].extend([pair[1] for pair in pairs_same_class])\n    pair_data['label'].extend([1] * len(pairs_same_class))\n\nfor label1, label2 in combinations(unique_labels, 2):\n    samples_with_label1 = df[df['label'] == label1]\n    samples_with_label2 = df[df['label'] == label2]\n    pairs_diff_class = [(text1, text2) for text1 in samples_with_label1['text'] for text2 in samples_with_label2['text']]\n    pair_data['text1'].extend([pair[0] for pair in pairs_diff_class])\n    pair_data['text2'].extend([pair[1] for pair in pairs_diff_class])\n    pair_data['label'].extend([-1] * len(pairs_diff_class))\n    \nnew_df = pd.DataFrame(pair_data)\nnew_df = new_df.sample(frac = 1)\nnew_df.reset_index(drop = True , inplace = True)\nnew_df.label = new_df.label.astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.label.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# only take a sample\n# dataset = pd.concat((new_df[lambda x : x.label == 1.0].sample(619283),new_df[lambda x : x.label == -1.0].sample(619283)))\n# del new_df\n# import gc\n# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LoggingCS(losses.CosineSimilarityLoss):\n    def forward(self, sentence_features, labels):\n        loss_value = super().forward(sentence_features, labels)\n        _losses.append(loss_value.item())\n        return loss_value\n_losses = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nfrom sentence_transformers.util import cos_sim\nimport numpy as np\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer, util , InputExample\nfrom torch.utils.data import DataLoader\nfrom sentence_transformers import SentenceTransformer, LoggingHandler , losses, models\n\nsimilarity_dataset = new_df\n\ntrain_samples = []\n\nfor row in tqdm(similarity_dataset.itertuples()):\n    train_samples.append(InputExample(texts=[row[1] , row[2]], label=row[3]))\n    \nfrom torch.utils.data import DataLoader\nbatch_size = 230\n\ntrain_dataloader = DataLoader(train_samples, shuffle=True, batch_size=batch_size)\nmodel = SentenceTransformer(\"\" )\nmodel._first_module().max_seq_length = 50\n\ntrain_loss = LoggingCS(model=model)\nepochs = 1\nlr = 2e-5\nmodel.fit( train_objectives = [(train_dataloader , train_loss)],\n          epochs=epochs, \n          output_path='output_of_bert/' ,optimizer_params={'lr': lr} )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(_losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"login(\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi ,login\nmodel.save(\"my_model\")\napi = HfApi()\n\napi.upload_folder(\n    repo_id=\"\",\n    folder_path=\"\",\n    repo_type=\"model\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}